{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from collections import OrderedDict\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/toanne/Desktop/Brain-MRI-Segmentation/Brain-MRI-Segmentation/my_nnunet\n",
      "/Users/toanne/Desktop/Brain-MRI-Segmentation/Brain-MRI-Segmentation/data/input\n",
      "/Users/toanne/Desktop/Brain-MRI-Segmentation/Brain-MRI-Segmentation/data/segmentation\n"
     ]
    }
   ],
   "source": [
    "use_colab = False\n",
    "\n",
    "if use_colab:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive', force_remount=True)\n",
    "    sys.path.append('/content/drive/MyDrive/BrainMri')\n",
    "    os.getcwd()\n",
    "else:\n",
    "    root_dir = os.getcwd()\n",
    "\n",
    "my_nnunet_dir = os.path.join(root_dir, 'my_nnunet')\n",
    "input_dir = os.path.join(root_dir, 'data/input')\n",
    "segmentation_dir = os.path.join(root_dir, 'data/segmentation')\n",
    "print(my_nnunet_dir)\n",
    "print(input_dir)\n",
    "print(segmentation_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_if_not_exist(folder_path, overwrite=False):\n",
    "    \"\"\"\n",
    "    Create a folder if it does not exist.\n",
    "    \n",
    "    Args:\n",
    "        folder_path (str): relative path of the folder which needs to be created\n",
    "        overwrite (bool): Overwrite the existing folder if True. Defaults to False.\n",
    "    \"\"\"\n",
    "    if os.path.exists(folder_path):\n",
    "        if overwrite:\n",
    "            shutil.rmtree(folder_path)\n",
    "            os.makedirs(folder_path)\n",
    "            print(f'{folder_path} overwritten')\n",
    "        else:\n",
    "            print(f'{folder_path} already exists')\n",
    "    else:\n",
    "        os.makedirs(folder_path)\n",
    "        print(f'{folder_path} created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_nnunet already exists\n",
      "Current working directory: /Users/toanne/Desktop/Brain-MRI-Segmentation/Brain-MRI-Segmentation/my_nnunet\n"
     ]
    }
   ],
   "source": [
    "os.chdir(root_dir)\n",
    "create_if_not_exist('my_nnunet', overwrite=False)\n",
    "os.chdir('my_nnunet')\n",
    "print(f'Current working directory: {os.getcwd()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create 2 folders where we can put our input images and corresponding segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/toanne/Desktop/Brain-MRI-Segmentation/Brain-MRI-Segmentation/data/input created\n",
      "/Users/toanne/Desktop/Brain-MRI-Segmentation/Brain-MRI-Segmentation/data/segmentation created\n"
     ]
    }
   ],
   "source": [
    "create_if_not_exist(input_dir)\n",
    "create_if_not_exist(segmentation_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clone nnunet and install requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nnunet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/toanne/Desktop/Brain-MRI-Segmentation/Brain-MRI-Segmentation/my_nnunet'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/MIC-DKFZ/nnUNet.git\n",
    "!git clone https://github.com/NVIDIA/apex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/toanne/Desktop/Brain-MRI-Segmentation/Brain-MRI-Segmentation/my_nnunet'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_nnunet_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_dir = os.path.join(my_nnunet_dir, 'nnUNet')\n",
    "os.chdir(repo_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -e\n",
    "!pip install --upgrade git+https://github.com/nanohanno/hiddenlayer.git@bugfix/get_trace_graph#egg=hiddenlayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/toanne/Desktop/Brain-MRI-Segmentation/Brain-MRI-Segmentation/my_nnunet'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(my_nnunet_dir)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create all required folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = 'Task001'\n",
    "\n",
    "nnunet_dir = \"nnUNet/nnunet/nnUNet_raw_data_base/nnUNet_raw_data\"\n",
    "task_folder_name = os.path.join(nnunet_dir,task_name) \n",
    "train_image_dir = os.path.join(task_folder_name,'imagesTr') # path to training images\n",
    "train_label_dir = os.path.join(task_folder_name,'labelsTr') # path to training labels\n",
    "test_dir = os.path.join(task_folder_name,'imagesTs') # path to test images\n",
    "main_dir = os.path.join(my_nnunet_dir,'nnUNet/nnunet') # path to main directory\n",
    "trained_model_dir = os.path.join(main_dir, 'nnUNet_trained_models') # path to trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nnUNet/nnunet/nnUNet_raw_data_base/nnUNet_raw_data/Task001 created\n",
      "nnUNet/nnunet/nnUNet_raw_data_base/nnUNet_raw_data/Task001/imagesTr created\n",
      "nnUNet/nnunet/nnUNet_raw_data_base/nnUNet_raw_data/Task001/labelsTr created\n",
      "nnUNet/nnunet/nnUNet_raw_data_base/nnUNet_raw_data/Task001/imagesTs created\n",
      "/Users/toanne/Desktop/Brain-MRI-Segmentation/Brain-MRI-Segmentation/my_nnunet/nnUNet/nnunet/nnUNet_trained_models created\n"
     ]
    }
   ],
   "source": [
    "overwrite = False # Set this to True if you want to overwrite the folders\n",
    "create_if_not_exist(task_folder_name,overwrite = overwrite)\n",
    "create_if_not_exist(train_image_dir, overwrite = overwrite)\n",
    "create_if_not_exist(train_label_dir, overwrite = overwrite)\n",
    "create_if_not_exist(test_dir,overwrite= overwrite)\n",
    "create_if_not_exist(trained_model_dir, overwrite=overwrite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set env variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['nnUNet_raw_data_base'] = os.path.join(main_dir,'nnUNet_raw_data_base')\n",
    "os.environ['nnUNet_preprocessed'] = os.path.join(main_dir,'preprocessed')\n",
    "os.environ['RESULTS_FOLDER'] = trained_model_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Move files in training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_rename(old_loc, old_fname, new_loc, new_fname, delete_old=False):\n",
    "    \"\"\"\n",
    "    Copy a file from one location to another and rename it.\n",
    "    \n",
    "    Args:\n",
    "        old_loc (str): Old location of the file.\n",
    "        old_fname (str): Old name of the file.\n",
    "        new_loc (str): New location of the file.\n",
    "        new_fname (str): New name of the file.\n",
    "        delete_old (bool): Delete the old file if True. Defaults to False.\n",
    "    \"\"\"\n",
    "    old_file = os.path.join(old_loc, old_fname)\n",
    "    new_file = os.path.join(new_loc, new_fname)\n",
    "    shutil.copy(old_file, new_file)\n",
    "    if delete_old:\n",
    "        os.remove(old_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/toanne/Desktop/Brain-MRI-Segmentation/Brain-MRI-Segmentation/data/segmentation'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segmentation_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_all_files = os.listdir(segmentation_dir)\n",
    "list_of_all_files = [fname for fname in list_of_all_files if fname.endswith('.nii.gz')]\n",
    "\n",
    "for fname in list_of_all_files:\n",
    "    copy_rename(input_dir, fname, train_image_dir, fname)\n",
    "    copy_rename(segmentation_dir, fname, train_label_dir, fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_modality(fname):\n",
    "    end = fname.find('.nii.gz')\n",
    "    modality = fname[end-4:end]\n",
    "    for mod in modality:\n",
    "        if not(ord(mod) >= 48 and ord(mod) <= 57): # Check [0, 9]\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_for_single_modality(dir):\n",
    "    for file in os.listdir(dir):\n",
    "        if check_modality(file):\n",
    "            print(f'Modality present: {file}')\n",
    "        else:\n",
    "            new_name = file.replace('.nii.gz', '_0000.nii.gz')\n",
    "            os.rename(os.path.join(dir, file), os.path.join(dir, new_name))\n",
    "            print(f'Renamed to {new_name}')\n",
    "\n",
    "rename_for_single_modality(train_image_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overwrite_json_file = True # True if you want to overwrite the dataset.json file in Task_folder\n",
    "json_file_exist = False\n",
    "\n",
    "if os.path.exists(os.path.join(task_folder_name,'dataset.json')):\n",
    "    print('dataset.json already exist!')\n",
    "    json_file_exist = True\n",
    "\n",
    "if json_file_exist == False or overwrite_json_file:\n",
    "    json_dict = OrderedDict()\n",
    "    json_dict['name'] = task_name\n",
    "    json_dict['description'] = \"Segmentation of T1 Scans\"\n",
    "    json_dict['tensorImageSize'] = \"3D\"\n",
    "    json_dict['reference'] = \"\"\n",
    "    json_dict['licence'] = \"\"\n",
    "    json_dict['release'] = \"\"\n",
    "\n",
    "    # you may mention more than one modality\n",
    "    json_dict['modality'] = {\n",
    "        \"0\": \"MRI\"\n",
    "    }\n",
    "\n",
    "    # labels+1 should be mentioned for all the labels in the dataset\n",
    "    json_dict['labels'] = {\n",
    "        \"0\": \"Non Brain\",\n",
    "        \"1\": \"Cortical gray matter\",\n",
    "        \"2\": \"Cortical White matter\",\n",
    "        \"3\" : \"Cerebellum gray \",\n",
    "        \"4\" : \"Cerebellum white\"\n",
    "    }\n",
    "\n",
    "    train_ids = os.listdir(train_label_dir)\n",
    "    test_ids = os.listdir(test_dir)\n",
    "    json_dict['numTraining'] = len(train_ids)\n",
    "    json_dict['numTest'] = len(test_ids)\n",
    "\n",
    "    # no modality in train image and labels in dataset.json\n",
    "    json_dict['training'] = [{'image': \"./imagesTr/%s\" % i, \"label\": \"./labelsTr/%s\" % i} for i in train_ids]\n",
    "\n",
    "    # remove the modality from test image name to be saved in dataset.json\n",
    "    json_dict['test'] = [\"./imagesTs/%s\" % (i[:i.find(\"_0000\")]+'.nii.gz') for i in test_ids]\n",
    "\n",
    "    with open(os.path.join(task_folder_name,\"dataset.json\"), 'w') as f:\n",
    "        json.dump(json_dict, f, indent=4, sort_keys=True)\n",
    "\n",
    "    if os.path.exists(os.path.join(task_folder_name,'dataset.json')):\n",
    "        if json_file_exist==False:\n",
    "            print('dataset.json created!')\n",
    "        else:\n",
    "            print('dataset.json overwritten!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess the data for nnUNet format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -t 1 means \"Task001\", if you have a different task change it\n",
    "!nnUNet_plan_and_preprocess -t 1 --verify_dataset_integrity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 2D U net\n",
    "!nnUNet_train 2d nnUNetTrainerV2 1 0 --npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 3D full resolution U net\n",
    "!nnUNet_train 3d_fullres nnUNetTrainerV2 1 0 --npz "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 3D U-net cascade\n",
    "!nnUNet_train 3d_lowres nnUNetTrainerV2CascadeFullRes 1 0 --npz\n",
    "!nnUNet_train 3d_fullres nnUNetTrainerV2CascadeFullRes 1 0 --npz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the best config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!nnUNet_find_best_configuration -m 2d 3d_fullres 3d_lowres 3d_cascade_fullres -t 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_folder_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dir = os.path.join(task_folder_name, 'nnUNet_Prediction_Results')\n",
    "create_if_not_exist(result_dir, overwrite=True)\n",
    "\n",
    "# -i is the input folder\n",
    "# -o is where you want to save the predictions\n",
    "# -t 1 means task 1, change it if you have a different task number\n",
    "# Use -m 2d, or -m 3d_fullres, or -m 3d_cascade_fullres\n",
    "!nnUNet_predict -i /content/drive/MyDrive/neurosciences-segmentation/my_nnunet/nnUNet/nnunet/nnUNet_raw_data_base/nnUNet_raw_data/Task001/imagesTs -o /content/drive/MyDrive/neurosciences-segmentation/my_nnunet/nnUNet/nnunet/nnUNet_raw_data_base/nnUNet_raw_data/Task001/nnUNet_Prediction_Results -t 1 -tr nnUNetTrainerV2 -m 2d -f 0  --num_threads_preprocessing 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aio2024_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
